# =============================================================================
# Goose Configuration - Agent IA Autonome
# =============================================================================

provider: openai
model: groq/llama-3.3-70b-versatile

# OpenAI-compatible endpoint (via LiteLLM)
openai:
  base_url: http://litellm:4000/v1
  api_key: ${LITELLM_MASTER_KEY}

# Modèles disponibles
models:
  default: groq/llama-3.3-70b-versatile
  fast: groq/llama-3.1-8b-instant
  local: ollama/codellama
  coder: ollama/deepseek-coder

# Paramètres par défaut
temperature: 0.7
max_tokens: 4000

# Outils activés
tools:
  - name: bash
    description: Execute bash commands
    enabled: true
  
  - name: read_file
    description: Read file contents
    enabled: true
  
  - name: write_file
    description: Write or modify files
    enabled: true
  
  - name: list_directory
    description: List directory contents
    enabled: true
  
  - name: git
    description: Git operations
    enabled: true
  
  - name: docker
    description: Docker operations
    enabled: true
  
  - name: curl
    description: HTTP requests
    enabled: true

# Profils de tâches
profiles:
  coding:
    model: groq/llama-3.3-70b-versatile
    temperature: 0.3
    system_prompt: "You are an expert software engineer. Write clean, efficient, well-documented code."
  
  debug:
    model: groq/llama-3.3-70b-versatile
    temperature: 0.2
    system_prompt: "You are a debugging expert. Analyze errors carefully and suggest precise fixes."
  
  research:
    model: groq/llama-3.3-70b-versatile
    temperature: 0.7
    system_prompt: "You are a research assistant. Provide thorough, well-researched answers."
  
  creative:
    model: groq/llama-3.3-70b-versatile
    temperature: 0.9
    system_prompt: "You are a creative assistant. Think outside the box."

# Sécurité
safety:
  # Commandes interdites
  blocked_commands:
    - rm -rf /
    - dd if=/dev/zero
    - :(){ :|:& };:
  
  # Répertoires protégés
  protected_directories:
    - /
    - /etc
    - /sys
    - /proc
  
  # Demander confirmation pour actions dangereuses
  confirm_before:
    - rm
    - mv
    - git push
    - docker rm
    - docker stop

# Logging
logging:
  level: INFO
  format: json
  file: /workspace/.goose/logs/goose.log

# =============================================================================
# EXEMPLES D'UTILISATION
# =============================================================================
#
# 1. SESSION INTERACTIVE :
#    docker compose exec goose goose session
#
# 2. COMMANDE DIRECTE :
#    docker compose exec goose goose "Create a Python function to sort a list"
#
# 3. AVEC PROFIL :
#    docker compose exec goose goose --profile coding "Write a REST API"
#
# 4. MULTI-ÉTAPES :
#    docker compose exec goose goose "
#      1. Create a new Python project
#      2. Add FastAPI dependency
#      3. Create a hello world endpoint
#      4. Write tests
#      5. Create a Dockerfile
#    "
#
# 5. INTÉGRATION FORGEJO :
#    docker compose exec goose goose "
#      Clone the repo from Forgejo,
#      fix the bug in issue #42,
#      create a branch,
#      commit and push
#    "
#
# =============================================================================
