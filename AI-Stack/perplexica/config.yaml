# =============================================================================
# Perplexica Configuration - Recherche Web avec IA
# =============================================================================

[GENERAL]
PORT = 3001
SIMILARITY_MEASURE = "cosine"

[API_KEYS]
# LiteLLM via OpenAI-compatible endpoint
OPENAI = "${LITELLM_MASTER_KEY}"

[API_ENDPOINTS]
OPENAI = "http://litellm:4000/v1"
OLLAMA = "http://ollama:11434"

[CHAT_MODEL]
# Utiliser Groq via LiteLLM pour rapidité
PROVIDER = "openai"
MODEL = "groq/llama-3.3-70b-versatile"

[EMBEDDING_MODEL]
# Utiliser Ollama pour embeddings (gratuit, local)
PROVIDER = "ollama"
MODEL = "nomic-embed-text"

[SEARCH]
# Moteurs de recherche (DuckDuckGo par défaut)
ENGINES = ["duckduckgo"]

# Nombre de résultats
MAX_RESULTS = 10

[ADVANCED]
# Chunking pour RAG
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200

# Cache
ENABLE_CACHE = true
CACHE_TTL = 3600

# =============================================================================
# UTILISATION
# =============================================================================
# 
# Interface web : http://localhost:3001
# 
# Exemple de recherche :
# "What are the latest developments in AI code generation?"
# 
# Perplexica va :
# 1. Rechercher sur le web
# 2. Analyser les résultats avec l'IA
# 3. Générer une réponse synthétique avec sources
# 
# =============================================================================
