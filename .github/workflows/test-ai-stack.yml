name: Test AI Stack

on:
  workflow_dispatch:

env:
  COMPOSE_PROJECT_NAME: forgenest-ai-test

jobs:
  test-ai-stack:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: üì• Checkout du code
        uses: actions/checkout@v4

      - name: üêã Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: üìä Informations syst√®me
        run: |
          echo "=== üíª Informations Syst√®me ==="
          echo "CPU: $(nproc) cores"
          echo "RAM: $(free -h | grep Mem | awk '{print $2}')"
          echo "Disk: $(df -h / | tail -1 | awk '{print $4}') available"
          echo "Docker: $(docker --version)"
          echo "Docker Compose: $(docker compose version)"

      - name: ‚öôÔ∏è Cr√©er fichier .env pour tests
        working-directory: AI-Stack
        run: |
          cat > .env << 'EOF'
          # Ports
          LITELLM_PORT=4000
          LANGFUSE_PORT=3002
          CLICKHOUSE_PORT=8123
          CLICKHOUSE_MIGRATION_PORT=9000
          WEBUI_PORT=3000
          PERPLEXICA_PORT=3001
          AI_GATEWAY_PORT=8000
          TABBY_PORT=8080
          OLLAMA_PORT=11434
          
          # LiteLLM
          LITELLM_MASTER_KEY=sk-test-1234567890
          
          # Langfuse - PostgreSQL
          LANGFUSE_DB_PASSWORD=test_password_secure_123
          LANGFUSE_NEXTAUTH_SECRET=test-nextauth-secret-min-32-chars-for-testing
          LANGFUSE_SALT=test-salt-secret-min-32-chars-for-testing
          LANGFUSE_PUBLIC_KEY=
          LANGFUSE_SECRET_KEY=
          
          # ClickHouse - ALIGN√â AVEC L'OFFICIEL LANGFUSE
          CLICKHOUSE_URL=http://clickhouse:8123
          CLICKHOUSE_MIGRATION_URL=clickhouse://clickhouse:9000
          CLICKHOUSE_USER=default
          CLICKHOUSE_PASSWORD=clickhouse_test_pass
          CLICKHOUSE_DB=langfuse
          CLICKHOUSE_CLUSTER_ENABLED=false
          
          # Open WebUI
          WEBUI_SECRET_KEY=test-webui-secret-key-min-32-chars
          WEBUI_AUTH=false
          
          # Ollama
          OLLAMA_MODELS=llama3.2:1b
          OLLAMA_NUM_GPU=0
          OLLAMA_NUM_CTX=2048
          
          # Tabby
          TABBY_MODEL=StarCoder-1B
          TABBY_DEVICE=cpu
          
          # Goose
          GOOSE_MODEL=ollama/llama3.2
          
          # Volumes
          VOLUMES_BASE=./volumes
          
          # APIs externes
          GROQ_API_KEY=
          HUGGINGFACE_API_KEY=
          TOGETHER_API_KEY=
          OPENROUTER_API_KEY=
          EOF
          
          echo "‚úÖ Fichier .env cr√©√© (align√© avec l'officiel Langfuse)"
          cat .env

      - name: üî® Build des images Docker
        working-directory: AI-Stack
        run: |
          echo "=== üî® Build des images ==="
          docker compose build --no-cache ai-gateway goose
          echo "‚úÖ Build termin√©"

      - name: üöÄ D√©marrer les services avec depends_on
        working-directory: AI-Stack
        run: |
          echo "=== üöÄ D√©marrage des services ==="
          echo "‚ÑπÔ∏è  Docker Compose utilisera depends_on et healthchecks"
          
          # D√©marrer TOUS les services - docker compose respectera depends_on
          docker compose up -d redis clickhouse langfuse-db langfuse ollama litellm ai-gateway
          
          echo "‚è≥ Attente que tous les services soient healthy..."
          sleep 60
          
          echo "‚úÖ Services d√©marr√©s"

      - name: üìä V√©rifier l'√©tat des services
        working-directory: AI-Stack
        run: |
          echo "=== üìä √âtat des services ==="
          docker compose ps
          
          echo ""
          echo "=== üìã Logs ClickHouse (20 derni√®res lignes) ==="
          docker compose logs clickhouse --tail 20
          
          echo ""
          echo "=== üìã Logs Langfuse (30 derni√®res lignes) ==="
          docker compose logs langfuse --tail 30

      - name: üì• T√©l√©charger mod√®le Ollama
        working-directory: AI-Stack
        run: |
          echo "=== üì• T√©l√©chargement mod√®le Ollama ==="
          docker compose exec -T ollama ollama pull llama3.2:1b
          docker compose exec -T ollama ollama list
          echo "‚úÖ Mod√®le t√©l√©charg√©"

      - name: üß™ Test 1/10 - Redis Cache
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test Redis ==="
          PING_RESULT=$(docker compose exec -T redis redis-cli ping)
          if [ "$PING_RESULT" = "PONG" ]; then
            echo "  ‚úÖ Redis OK"
          else
            exit 1
          fi

      - name: üß™ Test 2/10 - Langfuse Analytics
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test Langfuse ==="
          HEALTH=$(curl -sf http://localhost:3002/api/public/health)
          if echo "$HEALTH" | grep -q "status"; then
            echo "  ‚úÖ Langfuse health OK"
          else
            echo "  ‚ùå Langfuse health √©choue"
            exit 1
          fi

      - name: üß™ Test 3/10 - ClickHouse Database
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test ClickHouse ==="
          if curl -sf http://localhost:8123/ping >/dev/null 2>&1; then
            echo "  ‚úÖ ClickHouse r√©pond"
          else
            exit 1
          fi
          
          RESULT=$(curl -sf "http://localhost:8123/?query=SELECT%20version()")
          echo "  ‚úÖ ClickHouse version: $RESULT"

      - name: üß™ Test 4/10 - Ollama LLM
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test Ollama ==="
          TAGS=$(curl -sf http://localhost:11434/api/tags)
          if echo "$TAGS" | grep -q "llama3.2"; then
            echo "  ‚úÖ Ollama OK"
          else
            exit 1
          fi

      - name: üß™ Test 5/10 - LiteLLM Proxy
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test LiteLLM ==="
          RESPONSE=$(curl -sf http://localhost:4000/v1/chat/completions \
            -H "Authorization: Bearer sk-test-1234567890" \
            -H "Content-Type: application/json" \
            -d '{"model": "ollama/llama3.2", "messages": [{"role": "user", "content": "Hi"}], "max_tokens": 5}')
          
          if echo "$RESPONSE" | grep -q "choices"; then
            echo "  ‚úÖ LiteLLM OK"
          else
            exit 1
          fi

      - name: üß™ Test 6/10 - AI Gateway
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test AI Gateway ==="
          HEALTH=$(curl -sf http://localhost:8000/health)
          if echo "$HEALTH" | grep -q "status\|healthy"; then
            echo "  ‚úÖ AI Gateway OK"
          else
            exit 1
          fi

      - name: üß™ Test 7/10 - Goose Agent
        working-directory: AI-Stack
        continue-on-error: true
        run: |
          echo "=== üß™ Test Goose ==="
          docker compose up -d goose
          sleep 5
          if docker compose ps goose | grep -q "Up\|running"; then
            echo "  ‚úÖ Goose OK"
          fi

      - name: üß™ Test 8/10 - Tabby
        working-directory: AI-Stack
        continue-on-error: true
        run: |
          echo "=== üß™ Test Tabby (optionnel) ==="
          docker compose up -d tabby
          sleep 30
          if curl -sf http://localhost:8080/v1/health >/dev/null 2>&1; then
            echo "  ‚úÖ Tabby OK"
          else
            echo "  ‚è≠Ô∏è Tabby skip"
          fi

      - name: üß™ Test 9/10 - Open WebUI
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test Open WebUI ==="
          docker compose up -d open-webui
          sleep 15
          
          UI_STATUS=$(curl -sf -o /dev/null -w "%{http_code}" http://localhost:3000/)
          if [ "$UI_STATUS" -eq 200 ] || [ "$UI_STATUS" -eq 302 ]; then
            echo "  ‚úÖ Open WebUI accessible (code: $UI_STATUS)"
          else
            exit 1
          fi

      - name: üß™ Test 10/10 - Int√©gration E2E
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test E2E ==="
          RESPONSE=$(curl -sf http://localhost:4000/v1/chat/completions \
            -H "Authorization: Bearer sk-test-1234567890" \
            -H "Content-Type: application/json" \
            -d '{"model": "ollama/llama3.2", "messages": [{"role": "user", "content": "test"}], "max_tokens": 10}')
          
          if echo "$RESPONSE" | grep -q "choices"; then
            echo "  ‚úÖ E2E OK"
          else
            exit 1
          fi

      - name: üìä R√©sum√©
        if: always()
        working-directory: AI-Stack
        run: |
          echo ""
          echo "=========================================="
          echo "  üìä R√âSUM√â DES TESTS"
          echo "=========================================="
          docker compose ps
          echo ""
          echo "‚úÖ Tests termin√©s !"

      - name: üîç Logs de debug (si √©chec)
        if: failure()
        working-directory: AI-Stack
        run: |
          echo "=== üîç Logs de debug ==="
          echo "--- ClickHouse ---"
          docker compose logs clickhouse --tail 100
          echo ""
          echo "--- Langfuse ---"
          docker compose logs langfuse --tail 100

      - name: üßπ Nettoyage
        if: always()
        working-directory: AI-Stack
        run: |
          docker compose down -v
          docker system prune -f
          echo "‚úÖ Nettoyage termin√©"
