name: Test AI Stack

on:
  workflow_dispatch:
    paths:
      - 'AI-Stack/**'
      - '.github/workflows/test-ai-stack.yml'

env:
  COMPOSE_PROJECT_NAME: forgenest-ai-test

jobs:
  test-ai-stack:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      # ========================================================================
      # 1. PR√âPARATION
      # ========================================================================
      - name: üì• Checkout du code
        uses: actions/checkout@v4

      - name: üêã Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: üìä Informations syst√®me
        run: |
          echo "=== üíª Informations Syst√®me ==="
          echo "CPU: $(nproc) cores"
          echo "RAM: $(free -h | grep Mem | awk '{print $2}')"
          echo "Disk: $(df -h / | tail -1 | awk '{print $4}') available"
          echo "Docker: $(docker --version)"
          echo "Docker Compose: $(docker compose version)"
          echo ""

      # ========================================================================
      # 2. CONFIGURATION
      # ========================================================================
      - name: ‚öôÔ∏è Cr√©er fichier .env pour tests
        working-directory: AI-Stack
        run: |
          cat > .env << 'EOF'
          # Configuration de test - Valeurs minimales
          
          # Ports
          LITELLM_PORT=4000
          LANGFUSE_PORT=3002
          CLICKHOUSE_PORT=8123
          CLICKHOUSE_MIGRATION_PORT=9000
          WEBUI_PORT=3000
          PERPLEXICA_PORT=3001
          AI_GATEWAY_PORT=8000
          TABBY_PORT=8080
          OLLAMA_PORT=11434
          
          # LiteLLM
          LITELLM_MASTER_KEY=sk-test-1234567890
          
          # Langfuse - PostgreSQL
          LANGFUSE_DB_PASSWORD=test_password_secure_123
          LANGFUSE_NEXTAUTH_SECRET=test-nextauth-secret-min-32-chars-for-testing
          LANGFUSE_SALT=test-salt-secret-min-32-chars-for-testing
          LANGFUSE_PUBLIC_KEY=
          LANGFUSE_SECRET_KEY=
          
          # ClickHouse (obligatoire pour Langfuse v3+)
          CLICKHOUSE_URL=http://clickhouse:8123
          CLICKHOUSE_MIGRATION_URL=clickhouse://clickhouse:9000?username=default&password=&database=langfuse&x-multi-statement=true
          CLICKHOUSE_USER=default
          CLICKHOUSE_PASSWORD=
          CLICKHOUSE_DB=langfuse
          
          # Open WebUI
          WEBUI_SECRET_KEY=test-webui-secret-key-min-32-chars
          WEBUI_AUTH=false
          
          # Ollama - Mod√®le tr√®s l√©ger pour CI rapide
          OLLAMA_MODELS=llama3.2:1b
          OLLAMA_NUM_GPU=0
          OLLAMA_NUM_CTX=2048
          
          # Tabby - Mod√®le l√©ger
          TABBY_MODEL=StarCoder-1B
          TABBY_DEVICE=cpu
          
          # Goose
          GOOSE_MODEL=ollama/llama3.2
          
          # Volumes
          VOLUMES_BASE=./volumes
          
          # APIs externes (pas utilis√©es en test)
          GROQ_API_KEY=
          HUGGINGFACE_API_KEY=
          TOGETHER_API_KEY=
          OPENROUTER_API_KEY=
          EOF
          
          echo "‚úÖ Fichier .env cr√©√©"
          cat .env
      # ========================================================================
      # 3. BUILD
      # ========================================================================
      - name: üî® Build des images Docker
        working-directory: AI-Stack
        run: |
          echo "=== üî® Build des images ==="
          docker compose build --no-cache ai-gateway goose
          echo "‚úÖ Build termin√©"

      # ========================================================================
      # 4. D√âMARRAGE SERVICES CORE
      # ========================================================================
      - name: üöÄ D√©marrer les services core (sans Perplexica)
        working-directory: AI-Stack
        run: |
          echo "=== üöÄ D√©marrage des services core ==="
          docker compose up -d redis langfuse-db langfuse ollama litellm ai-gateway
          echo "‚úÖ Services core d√©marr√©s"
          
      - name: ‚è≥ Attendre que les services core soient pr√™ts
        working-directory: AI-Stack
        run: |
          echo "=== ‚è≥ Attente sant√© des services core ==="
          
          # Fonction pour attendre un service
          wait_for_service() {
            SERVICE=$1
            URL=$2
            MAX_ATTEMPTS=300
            ATTEMPT=0
            
            echo "Attente de $SERVICE..."
            while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
              if curl -sf "$URL" >/dev/null 2>&1; then
                echo "  ‚úÖ $SERVICE est pr√™t"
                return 0
              fi
              ATTEMPT=$((ATTEMPT + 1))
              echo "  ‚è≥ Tentative $ATTEMPT/$MAX_ATTEMPTS..."
              sleep 5
            done
            
            echo "  ‚ùå $SERVICE n'est pas pr√™t apr√®s $MAX_ATTEMPTS tentatives"
            return 1
          }
          
          # Attendre Redis
          echo "Test Redis..."
          docker compose exec -T redis redis-cli ping || exit 1
          echo "  ‚úÖ Redis OK"
          
          # Attendre Langfuse DB
          sleep 10
          echo "  ‚úÖ Langfuse DB OK"
          
          # Attendre Langfuse
          wait_for_service "Langfuse" "http://localhost:3002/api/public/health" || exit 1
          
          # Attendre Ollama
          wait_for_service "Ollama" "http://localhost:11434/api/tags" || exit 1
          
          # Attendre LiteLLM
          wait_for_service "LiteLLM" "http://localhost:4000/health" || exit 1
          
          # Attendre AI Gateway
          wait_for_service "AI Gateway" "http://localhost:8000/health" || exit 1
          
          echo ""
          echo "‚úÖ Tous les services core sont pr√™ts !"

      # ========================================================================
      # 5. T√âL√âCHARGEMENT MOD√àLE OLLAMA
      # ========================================================================
      - name: üì• T√©l√©charger mod√®le Ollama
        working-directory: AI-Stack
        run: |
          echo "=== üì• T√©l√©chargement mod√®le Ollama ==="
          echo "T√©l√©chargement de llama3.2:1b (petit mod√®le pour tests)..."
          
          docker compose exec -T ollama ollama pull llama3.2:1b
          
          echo ""
          echo "Mod√®les disponibles :"
          docker compose exec -T ollama ollama list
          echo "‚úÖ Mod√®le t√©l√©charg√©"

      # ========================================================================
      # 6. TESTS REDIS CACHE
      # ========================================================================
      - name: üß™ Test 1/10 - Redis Cache
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test Redis Cache ==="
          
          # Test ping
          PING_RESULT=$(docker compose exec -T redis redis-cli ping)
          if [ "$PING_RESULT" = "PONG" ]; then
            echo "  ‚úÖ Redis r√©pond correctement"
          else
            echo "  ‚ùå Redis ne r√©pond pas"
            exit 1
          fi
          
          # Test set/get
          docker compose exec -T redis redis-cli set test_key "test_value"
          VALUE=$(docker compose exec -T redis redis-cli get test_key)
          if echo "$VALUE" | grep -q "test_value"; then
            echo "  ‚úÖ Redis peut stocker et r√©cup√©rer des donn√©es"
          else
            echo "  ‚ùå Redis set/get √©choue"
            exit 1
          fi
          
          echo "‚úÖ Test Redis Cache r√©ussi"

      # ========================================================================
      # 7. TESTS LANGFUSE
      # ========================================================================
      - name: üß™ Test 2/10 - Langfuse Analytics
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test Langfuse ==="
          
          # Test health
          HEALTH=$(curl -sf http://localhost:3002/api/public/health)
          if echo "$HEALTH" | grep -q "status"; then
            echo "  ‚úÖ Langfuse health endpoint OK"
          else
            echo "  ‚ùå Langfuse health endpoint √©choue"
            exit 1
          fi
          
          # Test UI accessible
          UI_STATUS=$(curl -sf -o /dev/null -w "%{http_code}" http://localhost:3002/)
          if [ "$UI_STATUS" -eq 200 ] || [ "$UI_STATUS" -eq 302 ]; then
            echo "  ‚úÖ Langfuse UI accessible (code: $UI_STATUS)"
          else
            echo "  ‚ùå Langfuse UI non accessible (code: $UI_STATUS)"
            exit 1
          fi
          
          echo "‚úÖ Test Langfuse r√©ussi"

      # ========================================================================
      # 8. TESTS OLLAMA
      # ========================================================================
      - name: üß™ Test 3/10 - Ollama LLM Local
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test Ollama ==="
          
          # Liste des mod√®les
          MODELS=$(curl -sf http://localhost:11434/api/tags)
          if echo "$MODELS" | grep -q "llama3.2"; then
            echo "  ‚úÖ Mod√®le llama3.2 trouv√©"
          else
            echo "  ‚ùå Mod√®le llama3.2 absent"
            echo "Mod√®les disponibles : $MODELS"
            exit 1
          fi
          
          # Test de g√©n√©ration
          echo "  Test g√©n√©ration de texte..."
          RESPONSE=$(curl -sf http://localhost:11434/api/generate -d '{
            "model": "llama3.2:1b",
            "prompt": "Say hello in one word",
            "stream": false
          }')
          
          if echo "$RESPONSE" | grep -q "response"; then
            echo "  ‚úÖ Ollama peut g√©n√©rer du texte"
            GENERATED=$(echo "$RESPONSE" | jq -r '.response' | head -c 50)
            echo "  Exemple g√©n√©r√©: $GENERATED..."
          else
            echo "  ‚ùå Ollama g√©n√©ration √©choue"
            echo "R√©ponse: $RESPONSE"
            exit 1
          fi
          
          echo "‚úÖ Test Ollama r√©ussi"

      # ========================================================================
      # 9. TESTS LITELLM PROXY
      # ========================================================================
      - name: üß™ Test 4/10 - LiteLLM Proxy + Cache
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test LiteLLM ==="
          
          # Test health
          HEALTH=$(curl -sf http://localhost:4000/health)
          if echo "$HEALTH" | grep -q "healthy"; then
            echo "  ‚úÖ LiteLLM health OK"
          else
            echo "  ‚ö†Ô∏è LiteLLM health check non standard"
          fi
          
          # Test liste des mod√®les
          MODELS=$(curl -sf http://localhost:4000/v1/models \
            -H "Authorization: Bearer sk-test-1234567890")
          
          if echo "$MODELS" | grep -q "ollama"; then
            echo "  ‚úÖ LiteLLM expose les mod√®les Ollama"
          else
            echo "  ‚ö†Ô∏è Aucun mod√®le Ollama trouv√©"
          fi
          
          # Test g√©n√©ration via LiteLLM
          echo "  Test g√©n√©ration via LiteLLM..."
          RESPONSE=$(curl -sf http://localhost:4000/v1/chat/completions \
            -H "Authorization: Bearer sk-test-1234567890" \
            -H "Content-Type: application/json" \
            -d '{
              "model": "ollama/llama3.2",
              "messages": [{"role": "user", "content": "Hi"}],
              "max_tokens": 10
            }')
          
          if echo "$RESPONSE" | grep -q "choices"; then
            echo "  ‚úÖ LiteLLM peut router vers Ollama"
          else
            echo "  ‚ùå LiteLLM routing √©choue"
            echo "R√©ponse: $RESPONSE"
            exit 1
          fi
          
          # Test cache (m√™me requ√™te 2x)
          echo "  Test cache Redis..."
          START1=$(date +%s%N)
          curl -sf http://localhost:4000/v1/chat/completions \
            -H "Authorization: Bearer sk-test-1234567890" \
            -H "Content-Type: application/json" \
            -d '{
              "model": "ollama/llama3.2",
              "messages": [{"role": "user", "content": "Cache test 123"}],
              "max_tokens": 5
            }' > /dev/null
          END1=$(date +%s%N)
          TIME1=$(( (END1 - START1) / 1000000 ))
          
          sleep 2
          
          START2=$(date +%s%N)
          curl -sf http://localhost:4000/v1/chat/completions \
            -H "Authorization: Bearer sk-test-1234567890" \
            -H "Content-Type: application/json" \
            -d '{
              "model": "ollama/llama3.2",
              "messages": [{"role": "user", "content": "Cache test 123"}],
              "max_tokens": 5
            }' > /dev/null
          END2=$(date +%s%N)
          TIME2=$(( (END2 - START2) / 1000000 ))
          
          echo "  Temps requ√™te 1: ${TIME1}ms"
          echo "  Temps requ√™te 2: ${TIME2}ms (devrait √™tre plus rapide si cache actif)"
          
          if [ $TIME2 -lt $TIME1 ]; then
            echo "  ‚úÖ Cache fonctionne (requ√™te 2 plus rapide)"
          else
            echo "  ‚ö†Ô∏è Cache peut-√™tre inactif ou non mesurable"
          fi
          
          echo "‚úÖ Test LiteLLM r√©ussi"

      # ========================================================================
      # 10. TESTS AI GATEWAY
      # ========================================================================
      - name: üß™ Test 5/10 - AI Gateway API
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test AI Gateway ==="
          
          # Test health
          HEALTH=$(curl -sf http://localhost:8000/health)
          if echo "$HEALTH" | grep -q "healthy\|providers"; then
            echo "  ‚úÖ AI Gateway health OK"
          else
            echo "  ‚ùå AI Gateway health √©choue"
            exit 1
          fi
          
          # Test liste mod√®les
          MODELS=$(curl -sf http://localhost:8000/v1/models)
          if echo "$MODELS" | grep -q "ollama"; then
            echo "  ‚úÖ AI Gateway liste les mod√®les"
          else
            echo "  ‚ùå AI Gateway ne liste pas les mod√®les"
            exit 1
          fi
          
          # Test g√©n√©ration
          echo "  Test g√©n√©ration via AI Gateway..."
          RESPONSE=$(curl -sf http://localhost:8000/v1/chat/completions \
            -H "Content-Type: application/json" \
            -d '{
              "model": "ollama/llama3.2",
              "messages": [{"role": "user", "content": "Test"}],
              "max_tokens": 5
            }')
          
          if echo "$RESPONSE" | grep -q "choices\|content"; then
            echo "  ‚úÖ AI Gateway peut g√©n√©rer du texte"
          else
            echo "  ‚ùå AI Gateway g√©n√©ration √©choue"
            echo "R√©ponse: $RESPONSE"
            exit 1
          fi
          
          echo "‚úÖ Test AI Gateway r√©ussi"

      # ========================================================================
      # 11. TESTS GOOSE
      # ========================================================================
      - name: üß™ Test 6/10 - Goose Agent
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test Goose ==="
          
          # D√©marrer Goose
          docker compose up -d goose
          sleep 10
          
          # V√©rifier que Goose est d√©marr√©
          if docker compose ps goose | grep -q "Up\|running"; then
            echo "  ‚úÖ Goose conteneur d√©marr√©"
          else
            echo "  ‚ùå Goose conteneur non d√©marr√©"
            docker compose ps goose
            exit 1
          fi
          
          # Test commande Goose (version/help)
          if docker compose exec -T goose goose --version 2>&1 | grep -q "goose\|version\|command"; then
            echo "  ‚úÖ Goose CLI accessible"
          else
            echo "  ‚ö†Ô∏è Goose CLI version non d√©tectable (peut-√™tre normal)"
          fi
          
          # Test workspace
          if docker compose exec -T goose ls -la /workspace >/dev/null 2>&1; then
            echo "  ‚úÖ Goose workspace accessible"
          else
            echo "  ‚ùå Goose workspace non accessible"
            exit 1
          fi
          
          echo "‚úÖ Test Goose r√©ussi"

      # ========================================================================
      # 12. TESTS TABBY (optionnel car long)
      # ========================================================================
      - name: üß™ Test 7/10 - Tabby Autocompl√©tion (optionnel)
        working-directory: AI-Stack
        continue-on-error: true
        run: |
          echo "=== üß™ Test Tabby ==="
          echo "‚ö†Ô∏è Test optionnel (t√©l√©chargement mod√®le peut √™tre long)"
          
          # D√©marrer Tabby
          docker compose up -d tabby
          
          # Attendre max 3 minutes
          ATTEMPTS=0
          MAX_ATTEMPTS=36
          while [ $ATTEMPTS -lt $MAX_ATTEMPTS ]; do
            if curl -sf http://localhost:8080/v1/health >/dev/null 2>&1; then
              echo "  ‚úÖ Tabby est pr√™t"
              break
            fi
            ATTEMPTS=$((ATTEMPTS + 1))
            sleep 5
          done
          
          if [ $ATTEMPTS -eq $MAX_ATTEMPTS ]; then
            echo "  ‚è≠Ô∏è Tabby non pr√™t apr√®s 3 min (skip)"
            exit 0
          fi
          
          # Test health
          HEALTH=$(curl -sf http://localhost:8080/v1/health)
          if echo "$HEALTH" | grep -q "model\|device"; then
            echo "  ‚úÖ Tabby health OK"
          else
            echo "  ‚ö†Ô∏è Tabby health check non standard"
          fi
          
          echo "‚úÖ Test Tabby r√©ussi"

      # ========================================================================
      # 13. TESTS OPEN WEBUI
      # ========================================================================
      - name: üß™ Test 8/10 - Open WebUI
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test Open WebUI ==="
          
          # D√©marrer Open WebUI
          docker compose up -d open-webui
          sleep 15
          
          # Test health
          if curl -sf http://localhost:3000/health >/dev/null 2>&1; then
            echo "  ‚úÖ Open WebUI health OK"
          else
            echo "  ‚ö†Ô∏è Health endpoint peut ne pas exister"
          fi
          
          # Test UI accessible
          UI_STATUS=$(curl -sf -o /dev/null -w "%{http_code}" http://localhost:3000/)
          if [ "$UI_STATUS" -eq 200 ] || [ "$UI_STATUS" -eq 302 ]; then
            echo "  ‚úÖ Open WebUI accessible (code: $UI_STATUS)"
          else
            echo "  ‚ùå Open WebUI non accessible (code: $UI_STATUS)"
            exit 1
          fi
          
          echo "‚úÖ Test Open WebUI r√©ussi"

      # ========================================================================
      # 14. TESTS INT√âGRATION
      # ========================================================================
      - name: üß™ Test 9/10 - Int√©gration End-to-End
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test Int√©gration E2E ==="
          
          # Test: Open WebUI ‚Üí LiteLLM ‚Üí Ollama
          echo "  Test flux complet: WebUI ‚Üí LiteLLM ‚Üí Ollama"
          
          # Via LiteLLM (comme Open WebUI le ferait)
          RESPONSE=$(curl -sf http://localhost:4000/v1/chat/completions \
            -H "Authorization: Bearer sk-test-1234567890" \
            -H "Content-Type: application/json" \
            -d '{
              "model": "ollama/llama3.2",
              "messages": [{"role": "user", "content": "E2E test"}],
              "max_tokens": 10
            }')
          
          if echo "$RESPONSE" | grep -q "choices"; then
            echo "  ‚úÖ Flux complet fonctionne"
          else
            echo "  ‚ùå Flux E2E √©choue"
            exit 1
          fi
          
          # Test: AI Gateway routing
          echo "  Test routing AI Gateway"
          RESPONSE2=$(curl -sf http://localhost:8000/v1/chat/completions \
            -H "Content-Type: application/json" \
            -d '{
              "model": "ollama/llama3.2",
              "messages": [{"role": "user", "content": "Gateway test"}],
              "max_tokens": 5
            }')
          
          if echo "$RESPONSE2" | grep -q "choices\|content"; then
            echo "  ‚úÖ AI Gateway routing fonctionne"
          else
            echo "  ‚ùå AI Gateway routing √©choue"
            exit 1
          fi
          
          echo "‚úÖ Test Int√©gration E2E r√©ussi"

      # ========================================================================
      # 15. TESTS PERFORMANCE & M√âTRIQUES
      # ========================================================================
      - name: üß™ Test 10/10 - Performance & M√©triques
        working-directory: AI-Stack
        run: |
          echo "=== üß™ Test Performance ==="
          
          # Utilisation ressources
          echo "  Utilisation des ressources:"
          docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}" | head -12
          
          # Taille des volumes
          echo ""
          echo "  Taille des volumes:"
          du -sh volumes/* 2>/dev/null || echo "  Pas de volumes cr√©√©s"
          
          # Logs en erreur
          echo ""
          echo "  V√©rification des erreurs dans les logs:"
          ERROR_COUNT=$(docker compose logs 2>&1 | grep -i "error\|fatal\|exception" | grep -v "error_count" | wc -l)
          echo "  Erreurs trouv√©es: $ERROR_COUNT"
          
          if [ $ERROR_COUNT -gt 20 ]; then
            echo "  ‚ö†Ô∏è Beaucoup d'erreurs dans les logs ($ERROR_COUNT)"
            echo "  Principales erreurs:"
            docker compose logs 2>&1 | grep -i "error\|fatal" | head -10
          else
            echo "  ‚úÖ Peu d'erreurs ($ERROR_COUNT)"
          fi
          
          echo "‚úÖ Test Performance r√©ussi"

      # ========================================================================
      # 16. R√âSUM√â
      # ========================================================================
      - name: üìä R√©sum√© des tests
        if: always()
        working-directory: AI-Stack
        run: |
          echo ""
          echo "=========================================="
          echo "  üìä R√âSUM√â DES TESTS - STACK IA"
          echo "=========================================="
          echo ""
          echo "Services test√©s :"
          docker compose ps --format "table {{.Name}}\t{{.Status}}\t{{.Ports}}"
          echo ""
          echo "‚úÖ Tests termin√©s !"
          echo ""

      # ========================================================================
      # 17. DEBUG SI √âCHEC
      # ========================================================================
      - name: üîç Logs de debug (si √©chec)
        if: failure()
        working-directory: AI-Stack
        run: |
          echo "=== üîç Logs de debug ==="
          echo ""
          echo "--- Redis ---"
          docker compose logs redis --tail 50
          echo ""
          echo "--- Langfuse ---"
          docker compose logs langfuse --tail 50
          echo ""
          echo "--- ClickHouse ---"
          docker compose logs ai-clickhouse --tail 50
          √©cho ""
          echo "--- Ollama ---"
          docker compose logs ollama --tail 50
          echo ""
          echo "--- LiteLLM ---"
          docker compose logs litellm --tail 50
          echo ""
          echo "--- AI Gateway ---"
          docker compose logs ai-gateway --tail 50

      # ========================================================================
      # 18. NETTOYAGE
      # ========================================================================
      - name: üßπ Nettoyage
        if: always()
        working-directory: AI-Stack
        run: |
          echo "=== üßπ Nettoyage ==="
          docker compose down -v
          docker system prune -f
          echo "‚úÖ Nettoyage termin√©"
          
